{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streetcar Delay Prediction - XGBoost - REFACTORED\n",
    "\n",
    "GOAL: predict streetcar delays using XGBoost (for comparison with deep learning model)\n",
    "\n",
    "Refactored to look at delays by hour by day by route by direction\n",
    "\n",
    "Source dataset: : https://open.toronto.ca/dataset/ttc-streetcar-delay-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links to key parts of the notebook <a name='linkanchor' />\n",
    "<a href=#ingestdash>Ingest data</a>\n",
    "\n",
    "<a href=#definecategories>Define feature categories</a>\n",
    "\n",
    "<a href=#bookmark>Deal with missing values</a>\n",
    "\n",
    "<a href=#modelfit>Define and fit model</a>\n",
    "\n",
    "<a href=#reload>Reload saved model and weights</a>\n",
    "\n",
    "<a href=#confusionmatrix>Confusion matrix</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common imports and global variable definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common imports\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "# import datetime, timedelta\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date\n",
    "from dateutil import relativedelta\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "# DSX code to import uploaded documents\n",
    "from io import StringIO\n",
    "import requests\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import yaml\n",
    "import math\n",
    "import sys\n",
    "from subprocess import check_output\n",
    "from IPython.display import display\n",
    "#model libraries\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "#from tf.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "#import datetime\n",
    "#from datetime import date\n",
    "from sklearn import metrics\n",
    "# import pipeline libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from custom_classes import encode_categorical\n",
    "from custom_classes import prep_for_keras_input\n",
    "from custom_classes import fill_empty\n",
    "from custom_classes import encode_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory is: C:\\personal\\manning\\deep_learning_for_structured_data\\notebooks\n",
      "path_to_yaml C:\\personal\\manning\\deep_learning_for_structured_data\\notebooks\\streetcar_model_training_config.yml\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "current_path = os.getcwd()\n",
    "print(\"current directory is: \"+current_path)\n",
    "\n",
    "path_to_yaml = os.path.join(current_path, 'streetcar_model_training_config.yml')\n",
    "print(\"path_to_yaml \"+path_to_yaml)\n",
    "try:\n",
    "    with open (path_to_yaml, 'r') as c_file:\n",
    "        config = yaml.safe_load(c_file)\n",
    "except Exception as e:\n",
    "    print('Error reading the config file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date today 2020-04-09 23:48:04.205071\n",
      "start date 2014-01-01\n",
      "end date 2019-12-31\n"
     ]
    }
   ],
   "source": [
    "# load parameters\n",
    "\n",
    "testproportion = config['test_parms']['testproportion'] # proportion of data reserved for test set\n",
    "trainproportion = config['test_parms']['trainproportion'] # proportion of non-test data dedicated to training (vs. validation)\n",
    "verboseout = config['general']['verboseout']\n",
    "includetext = config['general']['includetext']\n",
    "\n",
    "presaved = config['general']['presaved']\n",
    "savemodel = config['general']['savemodel']\n",
    "picklemodel = config['general']['picklemodel']\n",
    "hctextmax = config['general']['hctextmax']\n",
    "maxwords = config['general']['maxwords']\n",
    "textmax = config['general']['textmax']\n",
    "\n",
    "targetthresh = config['general']['targetthresh']\n",
    "targetcontinuous = config['general']['targetcontinuous']\n",
    "\n",
    "#time of day thresholds\n",
    "time_of_day = {'overnight':{'start':0,'end':5},'morning_rush':{'start':5,'end':10},\n",
    "              'midday':{'start':10,'end':15},'aft_rush':{'start':15,'end':19},'evening':{'start':19,'end':24}}\n",
    "\n",
    "\n",
    "\n",
    "emptythresh = config['general']['emptythresh']\n",
    "zero_weight = config['general']['zero_weight']\n",
    "one_weight = config['general']['one_weight']\n",
    "one_weight_offset = config['general']['one_weight_offset']\n",
    "patience_threshold = config['general']['patience_threshold']\n",
    "\n",
    "\n",
    "# modifier for saved model elements\n",
    "modifier = config['general']['modifier']\n",
    "\n",
    "# control whether training controlled by early stop\n",
    "early_stop = True\n",
    "\n",
    "# default hyperparameter values\n",
    "learning_rate = config['hyperparameters']['learning_rate']\n",
    "dropout_rate = config['hyperparameters']['dropout_rate']\n",
    "l2_lambda = config['hyperparameters']['l2_lambda']\n",
    "loss_func = config['hyperparameters']['loss_func']\n",
    "output_activation = config['hyperparameters']['output_activation']\n",
    "batch_size = config['hyperparameters']['batch_size']\n",
    "epochs = config['hyperparameters']['epochs']\n",
    "\n",
    "# date values\n",
    "date_today = datetime.now()\n",
    "print(\"date today\",date_today)\n",
    "start_date =  date(config['general']['start_year'],config['general']['start_month'], config['general']['start_day'])\n",
    "print(\"start date\",start_date)\n",
    "end_date = date(config['general']['end_year'],config['general']['end_month'], config['general']['end_day'])\n",
    "print(\"end date\",end_date)\n",
    "\n",
    "\n",
    "# pickled original dataset and post-preprocessing dataset\n",
    "pickled_data_file = config['general']['pickled_data_file']\n",
    "pickled_dataframe = config['general']['pickled_dataframe']\n",
    "routedirection_file = config['general']['route_direction_file']\n",
    "\n",
    "# experiment parameter\n",
    "\n",
    "current_experiment = config['test_parms']['current_experiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_of_day = {'overnight':{'start':0,'end':5},'morning_rush':{'start':5,'end':10},\n",
    "#              'midday':{'start':10,'end':15},'aft_rush':{'start':15,'end':19},'evening':{'start':19,'end':23}}\n",
    "\n",
    "\n",
    "def get_time(hour):\n",
    "    for tod in time_of_day:\n",
    "        if (hour >= time_of_day[tod]['start']) and (hour < time_of_day[tod]['end']):\n",
    "            tod_out = tod\n",
    "    return(tod_out)\n",
    "\n",
    "def weekend_time(day, tod):\n",
    "    if (day=='Saturday') or (day=='Sunday'):\n",
    "        return('w'+tod)\n",
    "    else:\n",
    "        return(tod)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the paths required\n",
    "\n",
    "def get_path():\n",
    "    '''get the path for data files'''\n",
    "    rawpath = os.getcwd()\n",
    "    # data is in a directory called \"data\" that is a sibling to the directory containing the notebook\n",
    "    path = os.path.abspath(os.path.join(rawpath, '..', 'data'))\n",
    "    return(path)\n",
    "\n",
    "def get_pipeline_path():\n",
    "    '''get the path for data files'''\n",
    "    rawpath = os.getcwd()\n",
    "    # data is in a directory called \"data\" that is a sibling to the directory containing the notebook\n",
    "    path = os.path.abspath(os.path.join(rawpath, '..', 'pipelines'))\n",
    "    return(path)\n",
    "\n",
    "def get_model_path():\n",
    "    '''get the path for data files'''\n",
    "    rawpath = os.getcwd()\n",
    "    # data is in a directory called \"data\" that is a sibling to the directory containing the notebook\n",
    "    path = os.path.abspath(os.path.join(rawpath, '..', 'models'))\n",
    "    return(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_experiment_parameters(experiment_number, count_no_delay, count_delay):\n",
    "    ''' set the appropriate parameters for the experiment '''\n",
    "    print(\"setting parameters for experiment \", experiment_number)\n",
    "    # default settings for early stopping:\n",
    "    es_monitor = \"val_loss\"\n",
    "    es_mode = \"min\"\n",
    "    if experiment_number == 1:\n",
    "        #\n",
    "        early_stop = False\n",
    "        #\n",
    "        one_weight = 1.0\n",
    "        #\n",
    "        epochs = 10\n",
    "    elif experiment_number == 2:\n",
    "        #\n",
    "        early_stop = False\n",
    "        #\n",
    "        one_weight = 1.0\n",
    "        #\n",
    "        epochs = 50\n",
    "    elif experiment_number == 3:\n",
    "        #\n",
    "        early_stop = False\n",
    "        #\n",
    "        one_weight = (count_no_delay/count_delay) + one_weight_offset\n",
    "        #\n",
    "        epochs = 50\n",
    "    elif experiment_number == 4:\n",
    "        #\n",
    "        early_stop = True\n",
    "        es_monitor = \"val_loss\"\n",
    "        es_mode = \"min\"\n",
    "        #\n",
    "        one_weight = (count_no_delay/count_delay) + one_weight_offset\n",
    "        #\n",
    "        epochs = 50\n",
    "    elif experiment_number == 5:\n",
    "        #\n",
    "        early_stop = True\n",
    "        if sys.version_info >= (3,7):\n",
    "            es_monitor=\"val_accuracy\"\n",
    "        else:\n",
    "            es_monitor = \"val_acc\"\n",
    "        es_mode = \"max\"\n",
    "        #\n",
    "        one_weight = (count_no_delay/count_delay) + one_weight_offset\n",
    "        #\n",
    "        epochs = 50\n",
    "    else:\n",
    "        early_stop = True\n",
    "    return(early_stop, one_weight, epochs,es_monitor,es_mode)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest data and create refactored dataframe\n",
    "- Ingest data for route information and delay information\n",
    "- Create refactored dataframe with one row per route / direction / timeslot combination\n",
    "\n",
    "<a name='ingestdash' />\n",
    "<a href=#linkanchor>Back to link list</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load list of valid routes and directions into dataframe\n",
    "def ingest_data(path):\n",
    "    routedirection_frame = pd.read_csv(os.path.join(path,routedirection_file))\n",
    "    routedirection_frame.tail()\n",
    "    file_name = os.path.join(path,pickled_dataframe)\n",
    "    merged_data = pd.read_pickle(file_name)\n",
    "    merged_data.head()\n",
    "    return(routedirection_frame, merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add derived columns to merged_data dataframe\n",
    "def prep_merged_data(merged_data):\n",
    "    # define cols for year month day hour\n",
    "    merged_data['year'] = pd.DatetimeIndex(merged_data['Report Date']).year\n",
    "    merged_data['month'] = pd.DatetimeIndex(merged_data['Report Date']).month\n",
    "    merged_data['daym'] = pd.DatetimeIndex(merged_data['Report Date']).day\n",
    "    merged_data['hour'] = pd.DatetimeIndex(merged_data['Report Date Time']).hour\n",
    "    # define time of day column\n",
    "    merged_data['time_of_day'] = merged_data['hour'].apply(lambda x:get_time(x))\n",
    "    # add a special timeframe for weekends\n",
    "    merged_data['time_of_day'] = merged_data.apply(lambda x: weekend_time(x['Day'], x['time_of_day']), axis=1)\n",
    "    if targetcontinuous:\n",
    "        merged_data['target'] = merged_data['Min Delay']\n",
    "    else:\n",
    "        merged_data['target'] = np.where(merged_data['Min Delay'] >= targetthresh, 1, 0 )\n",
    "    return(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframe containing rows for each timeslot for each route for each direction\n",
    "# and merge with the input merged_data dataframe to get a result of a sparse dataframe with the\n",
    "# timeslot / route / direction combinations where delays occurred\n",
    "def prep_sparse_df(routedirection_frame, merged_data):\n",
    "    routedirection_frame['count'] = 0\n",
    "    print(\"routedirection\")\n",
    "    display(routedirection_frame[:5])\n",
    "    # define a dataframe with a row for each date to be covered\n",
    "    days = pd.date_range(start_date, end_date, freq='D')\n",
    "    date_frame = pd.DataFrame({'date':days,'count':0})\n",
    "    print(\"date_frame\")\n",
    "    display(date_frame[:5])\n",
    "    # define a dataframe with a row for each hour\n",
    "    hour_list = list(range(0,24))\n",
    "    hour_frame = pd.DataFrame({'hour':hour_list,'count':0})\n",
    "    print(\"hour_frame\")\n",
    "    display(hour_frame[:5])\n",
    "    #vprint(hour_frame.head())\n",
    "    # merge date_frame and routedirection\n",
    "    result1 = pd.merge(date_frame, routedirection_frame, on='count', how='outer')\n",
    "    print(\"result1\")\n",
    "    display(result1[:5])\n",
    "    # merge result1 with hour_frame\n",
    "    result2 = pd.merge(result1, hour_frame, on='count', how='outer')\n",
    "    result2 = result2.rename(columns={'date': 'Report Date'})\n",
    "    result2.Route = result2.Route.astype(str)\n",
    "    # segment the date\n",
    "    result2['year'] = pd.DatetimeIndex(result2['Report Date']).year\n",
    "    result2['month'] = pd.DatetimeIndex(result2['Report Date']).month\n",
    "    result2['daym'] = pd.DatetimeIndex(result2['Report Date']).day\n",
    "    result2['day'] = pd.DatetimeIndex(result2['Report Date']).weekday\n",
    "    print(\"result2\")\n",
    "    display(result2[:5])\n",
    "    print(\"merged_data before\")\n",
    "    display(merged_data[:5])\n",
    "    # drop extraneous columns from merged_data\n",
    "    merged_data = merged_data.drop(['Time',\n",
    "     'Report Date Time',\n",
    "     'year',\n",
    "     'month',\n",
    "     'daym',\n",
    "     'time_of_day','Min Gap','Location','Incident','Vehicle','target','Day'],axis=1)\n",
    "    print(\"merged_data after dropping extraneous columns\")\n",
    "    display(merged_data[:5])\n",
    "    # join result2 and the trimmed merged_data\n",
    "    result3 = pd.merge(result2,merged_data ,how='left', on=['Report Date','Route','Direction','hour'])\n",
    "    result3['Min Delay'].fillna(value=0.0,inplace=True)\n",
    "    result3['target'] = np.where(result3['Min Delay'] > 0.0, 1, 0 )\n",
    "    print(\"result3\")\n",
    "    display(result3[:5])\n",
    "    return(result3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFACTORED DATAFRAME SHOULD HAVE THE FOLLOWING COLUMNS:\n",
    "# DAY - for every day in the history from Jan 1 2014 to July 31 2018\n",
    "# HOUR - for every hour of the day\n",
    "#  for 501, regular route 5:00 am - midnight; 301 overnight\n",
    "#   for 503: 7- 10:00 am; 4-7:00 pm\n",
    "# for 504 5:00 am - 2:00 am; 304 overnight\n",
    "# for 505 5:00 am - 1:00 am\n",
    "# for 506 5:00 am - 1:00 am; 306 overnight\n",
    "# for 509 5:00 am - 1:00 am\n",
    "# for 510 5:00 am - 2:00 am; 310 overnight\n",
    "# for 511 5:00 am - 1:00 am\n",
    "# for 512 5:00 am - 2:00 am\n",
    "# for 514 (Cherry street)\n",
    "# ROUTE\n",
    "# DIRECTION\n",
    "# DELAY - where this could be count OR duration OR binary\n",
    "\n",
    "# example of filling in values:\n",
    "# data['PriceDate'] =  pd.to_datetime(data['PriceDate'], format='%m/%d/%Y')\n",
    "# data = data.sort_values(by=['PriceDate'], ascending=[True])\n",
    "# data.set_index('PriceDate', inplace=True)\n",
    "# print (data)\n",
    "\n",
    "# data = data.resample('D').ffill().reset_index()\n",
    "# print (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Prep Calls\n",
    "Contains calls to functions to load data, prep input dataframes, and create refactored dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path is C:\\personal\\manning\\deep_learning_for_structured_data\\data\n",
      "shape of pre refactored dataset (61500, 17)\n",
      "routedirection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Route</th>\n",
       "      <th>Direction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Route Direction  count\n",
       "0    301         e      0\n",
       "1    301         w      0\n",
       "2    301         b      0\n",
       "3    304         e      0\n",
       "4    304         e      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_frame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  count\n",
       "0 2014-01-01      0\n",
       "1 2014-01-02      0\n",
       "2 2014-01-03      0\n",
       "3 2014-01-04      0\n",
       "4 2014-01-05      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour_frame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hour  count\n",
       "0     0      0\n",
       "1     1      0\n",
       "2     2      0\n",
       "3     3      0\n",
       "4     4      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>count</th>\n",
       "      <th>Route</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>304</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>304</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  count  Route Direction\n",
       "0 2014-01-01      0    301         e\n",
       "1 2014-01-01      0    301         w\n",
       "2 2014-01-01      0    301         b\n",
       "3 2014-01-01      0    304         e\n",
       "4 2014-01-01      0    304         e"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report Date</th>\n",
       "      <th>count</th>\n",
       "      <th>Route</th>\n",
       "      <th>Direction</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>daym</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>e</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>e</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>e</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Report Date  count Route Direction  hour  year  month  daym  day\n",
       "0  2014-01-01      0   301         e     0  2014      1     1    2\n",
       "1  2014-01-01      0   301         e     1  2014      1     1    2\n",
       "2  2014-01-01      0   301         e     2  2014      1     1    2\n",
       "3  2014-01-01      0   301         e     3  2014      1     1    2\n",
       "4  2014-01-01      0   301         e     4  2014      1     1    2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_data before\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Incident</th>\n",
       "      <th>Location</th>\n",
       "      <th>Min Delay</th>\n",
       "      <th>Min Gap</th>\n",
       "      <th>Report Date</th>\n",
       "      <th>Route</th>\n",
       "      <th>Time</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>Report Date Time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>daym</th>\n",
       "      <th>hour</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Report Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-02 06:31:31</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>e</td>\n",
       "      <td>Late Leaving Garage</td>\n",
       "      <td>dundas and roncesvalles</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>505</td>\n",
       "      <td>06:31:00</td>\n",
       "      <td>4018</td>\n",
       "      <td>2014-01-02 06:31:31</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>morning_rush</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02 12:43:43</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>e</td>\n",
       "      <td>Utilized Off Route</td>\n",
       "      <td>king and shaw</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>504</td>\n",
       "      <td>12:43:00</td>\n",
       "      <td>4128</td>\n",
       "      <td>2014-01-02 12:43:43</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>midday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02 14:01:01</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>w</td>\n",
       "      <td>Held By</td>\n",
       "      <td>bingham and kingston road</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>501</td>\n",
       "      <td>14:01:00</td>\n",
       "      <td>4016</td>\n",
       "      <td>2014-01-02 14:01:01</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>midday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02 14:22:22</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>w</td>\n",
       "      <td>Investigation</td>\n",
       "      <td>king st. and roncesvalles</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>504</td>\n",
       "      <td>14:22:00</td>\n",
       "      <td>4175</td>\n",
       "      <td>2014-01-02 14:22:22</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>midday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02 16:42:42</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>e</td>\n",
       "      <td>Utilized Off Route</td>\n",
       "      <td>bathurst and king</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>504</td>\n",
       "      <td>16:42:00</td>\n",
       "      <td>4080</td>\n",
       "      <td>2014-01-02 16:42:42</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>aft_rush</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Day Direction             Incident  \\\n",
       "Report Date Time                                               \n",
       "2014-01-02 06:31:31  Thursday         e  Late Leaving Garage   \n",
       "2014-01-02 12:43:43  Thursday         e   Utilized Off Route   \n",
       "2014-01-02 14:01:01  Thursday         w              Held By   \n",
       "2014-01-02 14:22:22  Thursday         w        Investigation   \n",
       "2014-01-02 16:42:42  Thursday         e   Utilized Off Route   \n",
       "\n",
       "                                      Location  Min Delay  Min Gap  \\\n",
       "Report Date Time                                                     \n",
       "2014-01-02 06:31:31    dundas and roncesvalles        4.0      8.0   \n",
       "2014-01-02 12:43:43              king and shaw       20.0     22.0   \n",
       "2014-01-02 14:01:01  bingham and kingston road       13.0     19.0   \n",
       "2014-01-02 14:22:22  king st. and roncesvalles        7.0     11.0   \n",
       "2014-01-02 16:42:42          bathurst and king        3.0      6.0   \n",
       "\n",
       "                    Report Date Route      Time Vehicle    Report Date Time  \\\n",
       "Report Date Time                                                              \n",
       "2014-01-02 06:31:31  2014-01-02   505  06:31:00    4018 2014-01-02 06:31:31   \n",
       "2014-01-02 12:43:43  2014-01-02   504  12:43:00    4128 2014-01-02 12:43:43   \n",
       "2014-01-02 14:01:01  2014-01-02   501  14:01:00    4016 2014-01-02 14:01:01   \n",
       "2014-01-02 14:22:22  2014-01-02   504  14:22:00    4175 2014-01-02 14:22:22   \n",
       "2014-01-02 16:42:42  2014-01-02   504  16:42:00    4080 2014-01-02 16:42:42   \n",
       "\n",
       "                     year  month  daym  hour   time_of_day  target  \n",
       "Report Date Time                                                    \n",
       "2014-01-02 06:31:31  2014      1     2     6  morning_rush       0  \n",
       "2014-01-02 12:43:43  2014      1     2    12        midday       1  \n",
       "2014-01-02 14:01:01  2014      1     2    14        midday       1  \n",
       "2014-01-02 14:22:22  2014      1     2    14        midday       1  \n",
       "2014-01-02 16:42:42  2014      1     2    16      aft_rush       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_data after dropping extraneous columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Direction</th>\n",
       "      <th>Min Delay</th>\n",
       "      <th>Report Date</th>\n",
       "      <th>Route</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Report Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-02 06:31:31</th>\n",
       "      <td>e</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>505</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02 12:43:43</th>\n",
       "      <td>e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>504</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02 14:01:01</th>\n",
       "      <td>w</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>501</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02 14:22:22</th>\n",
       "      <td>w</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>504</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02 16:42:42</th>\n",
       "      <td>e</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>504</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Direction  Min Delay Report Date Route  hour\n",
       "Report Date Time                                                \n",
       "2014-01-02 06:31:31         e        4.0  2014-01-02   505     6\n",
       "2014-01-02 12:43:43         e       20.0  2014-01-02   504    12\n",
       "2014-01-02 14:01:01         w       13.0  2014-01-02   501    14\n",
       "2014-01-02 14:22:22         w        7.0  2014-01-02   504    14\n",
       "2014-01-02 16:42:42         e        3.0  2014-01-02   504    16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report Date</th>\n",
       "      <th>count</th>\n",
       "      <th>Route</th>\n",
       "      <th>Direction</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>daym</th>\n",
       "      <th>day</th>\n",
       "      <th>Min Delay</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>e</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>e</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>e</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Report Date  count Route Direction  hour  year  month  daym  day  Min Delay  \\\n",
       "0  2014-01-01      0   301         e     0  2014      1     1    2        0.0   \n",
       "1  2014-01-01      0   301         e     1  2014      1     1    2        0.0   \n",
       "2  2014-01-01      0   301         e     2  2014      1     1    2        0.0   \n",
       "3  2014-01-01      0   301         e     3  2014      1     1    2        0.0   \n",
       "4  2014-01-01      0   301         e     4  2014      1     1    2        0.0   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of refactored dataset (2952587, 11)\n",
      "count of no delay  2892594\n",
      "count of delay  59993\n",
      "setting parameters for experiment  5\n",
      "early_stop is  True\n",
      "one_weight is  48.21552514460021\n",
      "epochs is  50\n",
      "es_monitor is  val_accuracy\n",
      "es_mode is  max\n"
     ]
    }
   ],
   "source": [
    "# master calls\n",
    "# get the path for data files\n",
    "path = get_path()\n",
    "print(\"path is\",path)\n",
    "# load route direction and delay data datframes\n",
    "directions_df, merged_data = ingest_data(path)\n",
    "merged_data = prep_merged_data(merged_data)\n",
    "print(\"shape of pre refactored dataset\", merged_data.shape)\n",
    "merged_data['year'].value_counts()\n",
    "merged_data.groupby(['Route','Direction']).size().reset_index().rename(columns={0:'count'}).tail(50)\n",
    "# create refactored dataframe with one row for each route / direction / timeslot combination\n",
    "merged_data = prep_sparse_df(directions_df, merged_data)\n",
    "print(\"shape of refactored dataset\", merged_data.shape)\n",
    "count_no_delay = merged_data[merged_data['target']==0].shape[0]\n",
    "count_delay = merged_data[merged_data['target']==1].shape[0]\n",
    "print(\"count of no delay \",count_no_delay)\n",
    "print(\"count of delay \",count_delay)\n",
    "# define parameters for the current experiment\n",
    "experiment_number = 5\n",
    "early_stop, one_weight, epochs,es_monitor,es_mode = set_experiment_parameters(experiment_number, count_no_delay, count_delay)\n",
    "print(\"early_stop is \",early_stop)\n",
    "print(\"one_weight is \",one_weight)\n",
    "print(\"epochs is \",epochs)\n",
    "print(\"es_monitor is \",es_monitor)\n",
    "print(\"es_mode is \",es_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2952587, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define test / training sets; encode categorical values; process text field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training and test data set\n",
    "def get_train_validation_test(dataset):\n",
    "    train, test = train_test_split(dataset, test_size = testproportion)\n",
    "    dtrain, dvalid = train_test_split(train, random_state=123, train_size=trainproportion)\n",
    "    print(\"Through train test split. Test proportion:\")\n",
    "    print(testproportion)\n",
    "    return(dtrain,dvalid,test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define feature categories <a name='definecategories' />\n",
    "<a href=#linkanchor>Back to link list</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all cols ['Report Date', 'count', 'Route', 'Direction', 'hour', 'year', 'month', 'daym', 'day', 'Min Delay', 'target']\n"
     ]
    }
   ],
   "source": [
    "allcols = list(merged_data)\n",
    "print(\"all cols\",allcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the required column lists\n",
    "def def_col_lists():\n",
    "    textcols = [] # columns to deal with as text - replace entries with multiple IDs and use embeddings, RNN\n",
    "    continuouscols = [] # columns to deal with as continuous values - no embeddings\n",
    "    if targetcontinuous:\n",
    "        excludefromcolist = ['count','Report Date', 'target','count_md','Min Delay'] # columns to exclude completely from the model\n",
    "\n",
    "    else:\n",
    "        # if target column is not renamed Min Delay put Min Delay in exclusion list\n",
    "        excludefromcolist = ['count','Report Date', 'target','count_md', 'Min Delay'] # columns to exclude completely from the model\n",
    "    nontextcols = list(set(allcols) - set(textcols))\n",
    "    collist = list(set(nontextcols) - set(excludefromcolist) - set(continuouscols))\n",
    "    for col in continuouscols:\n",
    "        print(\"col is\",col)\n",
    "        merged_data[col] = merged_data[col].astype(float)\n",
    "        print(\"got through one\")\n",
    "        superset_data[col] = superset_data[col].astype(float)\n",
    "    # print column list lengths and contents:\n",
    "    print(\"allcols\",len(allcols))\n",
    "    print(\"excludefromcolist\",len(excludefromcolist))\n",
    "    print(excludefromcolist)\n",
    "    print(\"textcols\",len(textcols))\n",
    "    print(textcols)\n",
    "    print(\"continuouscols\",len(continuouscols))\n",
    "    print(continuouscols)\n",
    "    print(\"collist\",len(collist))\n",
    "    print(collist)\n",
    "    return(collist,continuouscols,textcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define keras variables\n",
    "\n",
    "\n",
    "# X for the features used\n",
    "\n",
    "def get_keras_vars(dataset):\n",
    "    X = {}\n",
    "    dictlist = []\n",
    "    for col in collist:\n",
    "        if verboseout:\n",
    "            print(\"cat col is\",col)\n",
    "        X[col] = np.array(dataset[col])\n",
    "        dictlist.append(np.array(dataset[col]))\n",
    "\n",
    "    for col in textcols:\n",
    "        if verboseout:\n",
    "            print(\"text col is\",col)\n",
    "        X[col] = pad_sequences(dataset[col], maxlen=max_dict[col])\n",
    "        dictlist.append(pad_sequences(dataset[col], maxlen=max_dict[col]))\n",
    "\n",
    "    for col in continuouscols:\n",
    "        if verboseout:\n",
    "            print(\"cont col is\",col)\n",
    "        X[col] = np.array(dataset[col])\n",
    "        dictlist.append(np.array(dataset[col]))\n",
    "\n",
    "    return X, dictlist\n",
    "\n",
    "def get_keras_list_only(X_in):\n",
    "    dictlist = []\n",
    "    for key, value in X_in.items():\n",
    "        print(\"X def loop key\",key)\n",
    "        print(\"value shape\",value.shape)\n",
    "        temp = [key,value]\n",
    "        dictlist.append(value)\n",
    "    return dictlist\n",
    "\n",
    "def get_keras_np(X_in):\n",
    "    return np.array(list(X_in.items()),dtype=object)\n",
    "# np.array(list(result.items()), dtype=dtype)\n",
    "\n",
    "# the deployment API for Watson Studio can only take a list/array, not a dictionary, so define list-only version for input\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allcols 11\n",
      "excludefromcolist 5\n",
      "['count', 'Report Date', 'target', 'count_md', 'Min Delay']\n",
      "textcols 0\n",
      "[]\n",
      "continuouscols 0\n",
      "[]\n",
      "collist 7\n",
      "['year', 'day', 'month', 'daym', 'Route', 'Direction', 'hour']\n",
      "fill empty xform\n",
      "col is  year\n",
      "col is  day\n",
      "col is  month\n",
      "col is  daym\n",
      "col is  Route\n",
      "col is  Direction\n",
      "col is  hour\n",
      "transform col is  year\n",
      "after transform col is  year\n",
      "transform col is  day\n",
      "after transform col is  day\n",
      "transform col is  month\n",
      "after transform col is  month\n",
      "transform col is  daym\n",
      "after transform col is  daym\n",
      "transform col is  Route\n",
      "after transform col is  Route\n",
      "transform col is  Direction\n",
      "after transform col is  Direction\n",
      "transform col is  hour\n",
      "after transform col is  hour\n",
      "Through train test split. Test proportion:\n",
      "0.2\n",
      "cat col is year\n",
      "cat col is day\n",
      "cat col is month\n",
      "cat col is daym\n",
      "cat col is Route\n",
      "cat col is Direction\n",
      "cat col is hour\n",
      "cat col is year\n",
      "cat col is day\n",
      "cat col is month\n",
      "cat col is daym\n",
      "cat col is Route\n",
      "cat col is Direction\n",
      "cat col is hour\n",
      "cat col is year\n",
      "cat col is day\n",
      "cat col is month\n",
      "cat col is daym\n",
      "cat col is Route\n",
      "cat col is Direction\n",
      "cat col is hour\n",
      "keras variables defined\n",
      "X_train_list [array([5, 2, 1, ..., 0, 3, 0], dtype=int64), array([5, 2, 2, ..., 6, 4, 2], dtype=int64), array([3, 0, 3, ..., 5, 8, 0], dtype=int64), array([12, 19, 21, ...,  0,  7,  7], dtype=int64), array([ 4,  8, 12, ...,  8,  6,  2]), array([0, 1, 0, ..., 4, 1, 1]), array([ 0, 17, 10, ...,  8, 15, 13], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "# master block to invoke pipeline\n",
    "\n",
    "# build fully qualified names for the files for saving the pipelines\n",
    "pipeline_path = get_pipeline_path()\n",
    "pipeline1_file_name = os.path.join(pipeline_path,'sc_delay_pipleline'+modifier+'.pkl')\n",
    "pipeline2_file_name = os.path.join(pipeline_path,'sc_delay_pipleline_keras_prep'+modifier+'.pkl')\n",
    "\n",
    "# define column lists:\n",
    "collist,continuouscols,textcols = def_col_lists()\n",
    "\n",
    "# create objects of the pipeline classes\n",
    "fe = fill_empty()\n",
    "ec = encode_categorical()\n",
    "pk = prep_for_keras_input()\n",
    "\n",
    "# need to implement the pipeline in two parts:\n",
    "# 1. fill empty + encode categoricals\n",
    "# 2. prep for Keras\n",
    "# because part 1 needs to be applied to the entire dataset and part 2 to the individual train, validate, and test sets\n",
    "\n",
    "\n",
    "sc_delay_pipeline = Pipeline([('fill_empty',fe),('encode_categorical',ec)])\n",
    "sc_delay_pipeline_keras_prep = Pipeline([('prep_for_keras',pk)])\n",
    "\n",
    "\n",
    "\n",
    "# provide the value for each parameter of each of the pipeline classes\n",
    "\n",
    "sc_delay_pipeline.set_params(fill_empty__collist = collist, fill_empty__continuouscols = continuouscols,\n",
    "                            fill_empty__textcols = textcols,encode_categorical__col_list = collist)\n",
    "sc_delay_pipeline_keras_prep.set_params(prep_for_keras__collist = collist,\n",
    "                            prep_for_keras__continuouscols = continuouscols,\n",
    "                            prep_for_keras__textcols = textcols)\n",
    "\n",
    "# fit the input dataset to the pipeline\n",
    "\n",
    "# first fit the first segment of pipeline on the whole dataset\n",
    "X = sc_delay_pipeline.fit_transform(merged_data)\n",
    "max_dict = ec.max_dict\n",
    "# then split dataset\n",
    "dump(sc_delay_pipeline, open(pipeline1_file_name,'wb'))\n",
    "dump(sc_delay_pipeline_keras_prep, open(pipeline2_file_name,'wb'))\n",
    "dtrain, dvalid, test = get_train_validation_test(X)\n",
    "# then apply second portion of pipeline to each subset\n",
    "\n",
    "X_train, X_train_list = get_keras_vars(dtrain)\n",
    "X_valid, X_valid_list = get_keras_vars(dvalid)\n",
    "X_test,X_test_list = get_keras_vars(test)\n",
    "\n",
    "print(\"keras variables defined\")\n",
    "print(\"X_train_list\",X_train_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and fit model <a name='modelfit' />\n",
    "- the deep learning model requires a list of numpy arrays\n",
    "- XGBoost requires a numpy array of lists, so the training and test datasets need to be transformed before the XGBoost model is fit\n",
    "\n",
    "<a href=#linkanchor>Back to link list</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lists of lists for the training and test datasets\n",
    "list_of_lists_train = []\n",
    "list_of_lists_test = []\n",
    "for i in range(0,7):\n",
    "    list_of_lists_train.append(X_train_list[i].tolist())\n",
    "    list_of_lists_test.append(X_test_list[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# convert lists of lists to numpy arrays of lists\n",
    "xgb_X_train = np.array(list_of_lists_train).T\n",
    "xgb_X_test = np.array(list_of_lists_test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  5,  3, ...,  4,  0,  0],\n",
       "       [ 2,  2,  0, ...,  8,  1, 17],\n",
       "       [ 1,  2,  3, ..., 12,  0, 10],\n",
       "       ...,\n",
       "       [ 0,  6,  5, ...,  8,  4,  8],\n",
       "       [ 3,  4,  8, ...,  6,  1, 15],\n",
       "       [ 0,  2,  0, ...,  2,  1, 13]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train XGBoost model using the same balancing factor as used for the deep learning model: one_weight\n",
    "model_path = get_model_path()\n",
    "xgb_save_model_path = os.path.join(model_path,'sc_xgbmodel'+modifier+\"_\"+str(experiment_number)+'.txt')\n",
    "model = XGBClassifier(scale_pos_weight=one_weight)\n",
    "model.fit(xgb_X_train, dtrain.target)\n",
    "model.save_model(xgb_save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply model to the test dataset\n",
    "y_pred = model.predict(xgb_X_test)\n",
    "xgb_predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.88%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "xgb_accuracy = accuracy_score(test.target, xgb_predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (xgb_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create charts for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# chart accuracy and loss for train and validation sets\\n\\nprint(modelfit.history.keys())\\n#  acc\\nplt.plot(modelfit.history['accuracy'])\\nplt.plot(modelfit.history['val_accuracy'])\\nplt.title('model accuracy')\\nplt.ylabel('accuracy')\\nplt.xlabel('epoch')\\nplt.legend(['train', 'validation'], loc='upper left')\\nplt.show()\\n# Loss\\nplt.plot(modelfit.history['loss'])\\nplt.plot(modelfit.history['val_loss'])\\nplt.title('model loss')\\nplt.ylabel('loss')\\nplt.xlabel('epoch')\\nplt.legend(['train', 'validation'], loc='upper left')\\nplt.show()\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# chart accuracy and loss for train and validation sets\n",
    "\n",
    "print(modelfit.history.keys())\n",
    "#  acc\n",
    "plt.plot(modelfit.history['accuracy'])\n",
    "plt.plot(modelfit.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# Loss\n",
    "plt.plot(modelfit.history['loss'])\n",
    "plt.plot(modelfit.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix <a name='confusionmatrix' />\n",
    "<a href=#linkanchor>Back to link list</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cfmap=metrics.confusion_matrix(y_true=test['target'],  # True labels\n",
    "                         y_pred=xgb_predictions)\n",
    "\n",
    "label = [\"0\", \"1\"]\n",
    "sns.heatmap(cfmap, annot = True, xticklabels = label, yticklabels = label)\n",
    "plt.xlabel(\"Prediction\")\n",
    "plt.title(\"Confusion Matrix for streetcar delay prediction (weighted)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "This notebook shows methods for dealing with structured data in the context of a simple XGBoost model.\n",
    "\n",
    "# Author\n",
    "\n",
    "Mark Ryan is a manager at Intact Insurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "try_tf2",
   "language": "python",
   "name": "try_tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
